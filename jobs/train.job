#!/bin/bash

#SBATCH --partition=gpu_titanrtx_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=TrainNLI
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=04:00:00
#SBATCH --mem=32000M
#SBATCH --output=jobs/slurm_output/train_%A.out

module purge
module load 2021
module load Anaconda3/2021.05

cd $HOME/NLI/
source activate nli

srun python -u nli/train.py --model avg_word_emb --epochs 10
# srun python -u nli/train.py --model max_pool_lstm --epochs 30